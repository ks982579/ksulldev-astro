---
layout: '@layouts/NotesLayout.astro'
title: 'Select Artificial Intelligence Techniques'
pubDate: 2023-10-16
description: 'We are now aiming our scopes at artificial intelligence with the weapon of data science.'
author: 'Kevin Sullivan'
tags: ["data science", "notes", "masters", "math", "maths"]
---

```yaml
title: Data Science
subtitle: DLMBDSA01
authors: Prof. Dr. Claudia Heß
publisher: IU International University of Applied Sciences
date: 2022
```

Not sure if this belongs here or in its own Artificial Intelligence section, but here is good for now. 

# Unit 6: Selected Artificial Intelligence Techniques

pp. 119 - 141

Learning objectives include:
+ Data classification by support vector machines.
+ The _feedforward_ neural network structure.
+ The back propagation algorithm in neural networks.
+ How to develop an artificial neural networks prediction model.
+ Recurrent networks and reinforcement learning.
+ Basics about Genetic Algorithms, Fuzzy Logic, and Naïve Bayes classification. 

## Introduction

Regression is the go-to supervised learning data science model. Then there's classification, where a prediction model is developed based on the input dataset in order to estimate the class of a new data record. 

This unit covers things from support vector machines and artificial neural networks, to fuzzy logic and genetic algorithms. A little bit of a shoutout, but "Intelligent Techniques for Data Science", by R. Akerar and P.S. Sajja covers most of these topics as well and provides a high-level overview of concepts and not diving too deeply in the math and implementation. 

## 6.1 - Support Vector Machines

**Definition - Support Vector Machines (SVM):** A supervised learning algorithm in machine learning that is typically used in classification problems. Can also be used in regression. 

Support Vector Machines is a binary linear classification technique where classification rule is to develop a linear function of the input dataset variables $\{x_{1,k}, x_{2,k},\dots,x_{M,k}\}$, with $k=1,2,\dots,N$, and $N$ and $M$ are the number of data records and data variables respectively. 

the classification function can be formulated as the linear equation:

$$
w \cdot x_i+b=0
$$

For an example, and I thought about this, we have a large group of people. We give them a test on a computer. If they pass the test, we consider them computer literate. If they fail, we don't. 

Our classification line will separate the dataset according to class, with one class on each side of it. 

There's also now a **separating channel**, which is the channel that has the classification line on its center line and is bounded by support vectors on both sides. It is generated by the classification line and defined by two lines parallel to it and equidestant from both sides, namely:

$$
\begin{align*}
+1 &= w \cdot x_i +b\\\\
\text{and}\\\\
-1 &= w \cdot x_i +b
\end{align*}
$$

Distance between support vector lines, or the width of the channel, is called the **margin**. **Support vectors** are data records $x_i$ that lie on either side of the separating channel. The margin is apparently denoted as $l$, a lower-case $L$. I'll denote below with var-phi $(\varphi)$ to avoid mistaking with number 1 or something:

$$
\begin{align*}
l = \varphi &= x_i^{+1} - x_i^{-1}\\
\therefore \varphi &= \frac{+1-b}{w}- \frac{-1-b}{w} = \frac{2}{\|w\|}
\end{align*}
$$

The SVM technique seeks the maximum margin to obtain the optimum separation between 2 classes. We seek classification equation that yields maximum $\frac{2}{\|w\|}$. 

### Kernel Trick

The _Kernel Trick_ helps SVM handle nonlinearly separable datasets. The dataset is projected onto a higher dimensional space unto which the dataset is linearly separable. The course book has a cool figure where a 2D dataset is projected into 3D and a linear plane can separate classes where a linear line could not. 

The SVM merely considers relative distance between data points in a _virtual_ projection space given by an appropriate Kernel function. Actual projection is apparently unnecessary. 

Common Kernel functions include:
+ polynomial
+ sigmoid
+ radial

There's a library for support vector machines called LIBSVM. Here's a pdf called [A Library for Support Vector Machines](https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf), and the library is at [www.csie.ntu.edu.tw](http://www.csie.ntu.edu.tw/~cjlin/libsvm). Should work with Python:

```bash
pip install -U libsvm-official
```

Additionally, [SciKit-Learn](https://scikit-learn.org/stable/modules/svm.html) apparently also has resources. 

## 6.2 - Artificial Neural Networks

p. 122

The purpose of developing an _artificial neural network_ (ANN) is to produce an artificial system capable of performing sophisticated calculations similar to the human brain. 

**Definition - Artificial Neural Network:** A computing network based on the neural networks of animal brains. It contains nodes and arrows. 

The response is encoded in how and to what degree various neurons are connected. The basic architecture comprises many layers of neurons:
+ Input layer for input values of the dataset variables.
+ Output layer for producing the value of the target variable. 
+ Intermediate layer (AKA hidden layers) to build more complex paths. 

**Deep learning** is the application of artificial neural networks to learning tasks with cascading hidden layers. The strength of a link between two neurons ($j$ and $i$) on two adjacent layers is represented by a weight values $w_{ji}$. The network adjusts weights of its links to produce output value close to the desired value of the target variable.

Somehow, the neuron sums its weighted inputs coming from its preceding links to get $a_i$ and then applies a transfer function to produce output $z_i$. 

$$
\begin{gather*}
a_i = \sum_{j=1}^M (w_{ji}\cdot z_j)\\
z_i = f(a_i)
\end{gather*}
$$

Note that the $z_j$ comes from the neurons before it, and $z_i$ is passed on to the next neuron. 

The _transfer function_ $(f)$ is also called an _activation function_. It must be continuous, differentiable, non-decreasing, and easy to compute. The neurons have mostly nonlinear activation functions which allow the network to learn nonlinear and linear relationships between the variables. 

I'll include the list of common activation functions because it's new to me:

**Linear (lin):** function generates outputs which are not confined to a specific range.

$$
z=a
$$

The graph is more like a $y=mx+b$ thing, but ok.

**log-sigmoid (logsig):** function generates outputs between 0 and 1

$$
z = \frac{1}{1+e^{-a}}
$$

That equations has an actuarial look to it. 

**Tan-sigmoid (tansig):** Function generates output between $-1 \le z \le +1$

$$
z = \tanh(a) = \frac{e^{2a}-1}{e^{2a}+1}
$$

**Exponential Linear Unit (ELU):** Function generates outputs that are not confined to a specific range. It has a linear shape for positive inputs and an exponential shape for negative outputs. 

$$
z = \left\{ 
\begin{array}{ll}
a & a \gt 0\\
\alpha (e^a-1) & a \le 0
\end{array}
\right.
$$

Alpha $(\alpha)$ is some positive values usually equal to $0.01$. 

**Rectified Linear Unit (ReLU):** Function generates outputs that are 0 for inputs with negative values and for all other inputs, the output will equal the input number.

$$
z = \max(a,\ 0)
$$

### Feedforward Networks

[Feedforward neural network | Wikipedia](https://en.wikipedia.org/wiki/Feedforward_neural_network): is on of the broad types of ANN characterized by the direction of the flow of information between its layers. The flow is _uni-directional_, meaning it only flows in one direction, which is forward, from input nodes to output nodes through hidden nodes (if any). Contrast to _recurrent neural network_, which have an bi-directional flow and we will look at later. Modern feedforward networks are trained using _backpropagation_ method, coming up soon, and are colloquially referred to as the "vanilla" neural networks. 

The Wikipedia article goes deeper into activation functions (both sigmoids), and then covers a brief history of the [perceptron | Wikipedia](https://en.wikipedia.org/wiki/Perceptron). 

[Feedforward Neural Networks | Brilliant](https://brilliant.org/wiki/feedforward-neural-networks/): These are ANNs where connections between units do not form a cycle. These were  first type of ANN invented and are simpler than their counterpart, the _recurrent neural network_. Information only travels forward in the network, there are no loops, first through input nodes, then through hidden nodes (if any), and finally through the output nodes. Primarily used for supervised learning where data to be learned is neither sequential nor time-dependent. 

[Feed Forward Neural Network | DeepAI](https://deepai.org/machine-learning-glossary-and-terms/feed-forward-neural-network): Same as other definitions, information flows forward and it is the simplest form of neural network. 

The number of neurons, number of hidden layers, and neurons' activation functions are completely arbitrary. Some feedforward network rules:
1. No connections within the neurons of a layer.
2. No direct connections between input layer and output layer. I guess that means at least one hidden layer.
3. Fully connected between layers. That is, each neuron in one layer is connected to all neurons in its succeeding layer.
4. Can have a number of hidden neurons per layer that is more or less than the number of inputs. 

So we specify the following:
+ Number of hidden layers.
+ Number of neurons within each hidden layer.
+ Activation function of each neuron.

And our network is ready to use a given dataset to self-learn. Per usual data science stuff, divide the dataset into training and testing, optionally a validation as well. The book suggest training at about 60% and testing around 40%, which seems like too much testing for me. 

A common learning algorithm is the back propagation algorithm. 

### Back Propagation Algorithm

p. 127

The **back propagation** algorithm is used to estimate a multilayer feedforward neural network's weights and develop a network model which estimates an output as accurately as possible, with respect to the given desired output. The desired output can be:
+ variable value for regression problems.
+ class value (e.g. $+1$ or $-1$) for classification problems.

I was going to make a _mermaid_ diagram of a simple neural network but that was too much. Each node in a layer points to all nodes in the next layer and has its value multiplied by a weight. 

$$
a_i = \sum_{j=0}^M \left( w_{ji} z_j \right)
$$

Above is the sum of weighted inputs flowing into a node. Below is the easy calculation of a node's output:

$$
z_j = f(a_j)
$$

We let $f(a)$ be the transfer function and $M$ be the number of neurons in layer $j$. 

The back propagation algorithm consists of the following 2 phases:
1. The forward pass.
2. The backward pass.

#### Forward Pass Phase

During the forward pass phase, the algorithm initially assumes random values for the weights and calculates all the network's parameters. It's named so because calculations proceed in a _forward_ direction from neuron to neuron, and layer to layer. 

The first hidden layer calculation is referred to as "forward pass iteration One". Subsequent layers are named accordingly if they exist. Poorly drawn looks like:

$$
\text{inputs} \rightarrow 
\begin{array}{c}
f_1(a) \\
f_2(a)\\
\vdots\\
f_n(a)
\end{array} \rightarrow \cdots \rightarrow 
f_{\Omega}(a) \rightarrow y
$$

The output of a network $(y)$, with the current set of weights, is compared to the desired target value $(d)$ to obtain the network error $(E)$. The network's weights are then updated to decrease the error metric in the next forward pass. 

##### Gradient Descent

This term should be familiar. Back propagation is uses gradient decent to recursively calculate the needed adjustments to the network weights. However, there is no analytical formula to do this in one step for all weights. Therefore, we work backwards through the layers to calculate how the weights need to be adjusted to reduce the error value. 

This cycle keeps repeating, a forward pass to calculate the error, and a backward pass to adjust network weights, until no more improvements can be made. 

Through a mathematical lens, we have the change in weight $\Delta w$ and the rate of decrease in error $\partial E / \partial w$ in the following equations:

$$
\begin{gather*}
\Delta w = - \eta \left( \frac{\partial E}{\partial w} \right)\\
w_{t+1} - w_t = - \eta \left( \frac{\partial E}{\partial w} \right)\\
w_{t+1} = w_t - \eta \left( \frac{\partial E}{\partial w} \right)\\
\end{gather*}
$$

Let $\eta$ be the proportional constant called the _learning rate_. You would keep $0 \lt \eta \lt 1$ usually because bigger step sizes could cause nonlinearity issues. 

The Network Error is defined by the mean square error between the network output $y$ and the desired output $d$ and averaged over the training data records:

$$
E = \frac{1}{2} \sum_{1}^n (d-y)^2
$$

The 1/2 is included to cancel out during the upcoming differentiation step. 

The change in error per weight between neuron $i$ and preceding neuron $j$ is obtained with the chain rule:

_Note: Math in computers is interesting, but buckle up, it's going to get a little wild_

$$
\begin{align*}
\frac{\partial E}{\partial w_{ji}} &= \frac{\partial E}{\partial z_{i}} \cdot
\frac{\partial z_i}{\partial a_{i}} \cdot
\frac{\partial a_i}{\partial w_{ji}}\\
&= \frac{\partial E}{\partial z_{i}} \cdot
\frac{\partial f(a_i)}{\partial a_{i}} \cdot
\frac{\partial 
\left(\sum_{j=0}^M \left( w_{ji} z_j \right)\right)
}{\partial w_{ji}}\\
&= \frac{\partial E}{\partial z_{i}} \cdot
\frac{\partial f(a_i)}{\partial a_{i}} \cdot
z_j\\
\end{align*}
$$

That makes sense with the substitution and cancelling of terms. 

Now, if the _neuron_ is in the output layer, we have:

$$
\begin{align*}
\frac{\partial E}{\partial z_i} &= \frac{\partial}{\partial z_i}
\left[
	\frac{1}{2}\sum_i^n (d-y)^2
\right]\\
&= \frac{\partial}{\partial z_i}
\left[
	\frac{1}{2}\sum_i^n (d-z_i)^2
\right]\\
&= -(d-z_i)\\ \\
\therefore \frac{\partial E}{\partial w_{ji}} &= \frac{\partial E}{\partial z_{i}} \cdot
\frac{\partial z_i}{\partial a_{i}} \cdot
\frac{\partial a_i}{\partial w_{ji}}\\
&= -(d-z_i) \cdot
\frac{\partial f(a_i)}{\partial a_{i}} \cdot
z_j\\
&= -\delta_i \cdot z_j
\end{align*}
$$

What happened at the end. Simple, we let

$$
\delta_i = (d-z_i)\cdot \frac{\partial f(a_i)}{\partial a_i}
$$

Weights in the output layer will be adjusted according to the following formula:

$$
(w_{ji})_{t+1} = (w_{ji})_{t} + \eta \cdot \delta_i \cdot z_i
$$

But, if the neuron $(i)$ is in the latest hidden layer, with links $(j)$ from its preceding layer and links $(u)$ to its succeeding layer (output):

$$
\begin{align*}
\frac{\partial E}{\partial w_{ji}} &= \frac{\partial E}{\partial z_{i}} \cdot
\frac{\partial z_i}{\partial a_{i}} \cdot
\frac{\partial a_i}{\partial w_{ji}}\\
&= \left(
	\sum_U \left[ 
		\frac{\partial E}{\partial z_{u}} \cdot
		\frac{\partial z_u}{\partial a_{u}} \cdot
		\frac{\partial a_u}{\partial z_{i}}
	\right]
\right) \cdot
\frac{\partial z_i}{\partial a_{i}} \cdot
\frac{\partial a_i}{\partial w_{ji}}\\
&= \left(
	\sum_U \left[ 
		\frac{\partial E}{\partial z_{u}} \cdot
		\frac{\partial f(a_u)}{\partial a_{u}} \cdot
		w_{iu}
	\right]
\right) \cdot
\frac{\partial f(a_i)}{\partial a_{i}} \cdot z_{j}\\
&= \left(
	\sum_U \left[ 
		-(d-z_u) \cdot
		\frac{\partial f(a_u)}{\partial a_{u}} \cdot
		w_{iu}
	\right]
\right) \cdot
\frac{\partial f(a_i)}{\partial a_{i}} \cdot z_{j}\\
&= \left(
	\sum_U \left[ 
		-\delta_u \cdot w_{iu}
	\right]
\right) \cdot
\frac{\partial f(a_i)}{\partial a_{i}} \cdot z_{j}\\
\therefore \frac{\partial E}{\partial w_{ji}} &= 
-\delta_i \cdot z_j
\end{align*}
$$

Where we let 

$$
\delta_i = \left(
	\sum_U \left[ 
		-\delta_u \cdot w_{iu}
	\right]
\right) \cdot
\frac{\partial f(a_i)}{\partial a_{i}}
$$

I use $U$ to represent the set of _succeeding layer neurons $(u)$_. 

Now, a quick recap: The weights of the links going to a hidden layer will be adjusted according to the following formula:

$$
(w_{ji})_{t+1} = (w_{ji})_t + \eta \cdot \delta_i \cdot z_j
$$

Where $\delta_i$ is defined right above. 

#### Backward Pass Phase

p. 133

We are now in the _backward pass phase_ of the back propagation algorithm. We move backward from the output layer and calculate the adjusted weights of the network. 

Let's list steps to compose the algorithm:

Step 1: Select a value for the learning rate (e.g. $\eta = 0.1$).

Step 2: For link connecting latest hidden layer's neuron $(j)$ to output of layer's neuron $(i)$, calculate the following:

$$
\delta_i = (d-z_i) \cdot \frac{\partial f(a_i)}{\partial a_i}
$$

Step 3: With delta, calculate the new weight as:

$$
(w_{ji})_{t+1} = (w_{ji})_t + \eta \cdot \delta_i \cdot z_j
$$

Repeat Steps 2 and 3 for all links from this hidden layer to the output layer.

Step 4: For the link between the _latest_ hidden layer's neuron $(i)$ and its preceding layer's neuron $(j)$ calculate $\delta_i$:

$$
\delta_i = \left( \sum_U \left[
\delta_u \cdot w_{iu}
\right] \right) \cdot \frac{\partial f(a_i)}{\partial a_i}
$$

Step 5: With another delta, calculate the new weight again 

$$
(w_{ji})_{t+1} = (w_{ji})_t + \eta \cdot \delta_i \cdot z_j
$$

Again, repeat steps 4 and 5 for all links connected to this hidden layer from its preceding layer.

Step 6: Repeat steps 4 and 5 in a backwards direction for the links between each remaining hidden layer's neuron $(i)$ and its preceding layer's neuron $(j)$ until the inputs' layer is reached. 

That is just on iteration of the back propagation algorithm where weights are adjusted only once. 

Step 7: Re-calculate the network error $(E)$ and check if it has reached a global minimum or a reasonable low value. If not, repeat the iteration until no additional improvement in the calculated network error can be made. 

interesting note: If a network's error cannot be improved and it has not reached its goal minimum value nor an acceptable value, we may consider changing the implemented neurons' activation functions. 
